---
title: 'PCA : an intuitive mathematical explanation '
date: 2021-10-05
permalink: /posts/2021/10/PCA-explanation/
excerpt: This blog post aims to give an intuitive explanation of PCA. <br/><img src='/images/PCA.jpg' style="width:370px;height:256px;">
tags:
  - PCA
  - Dimension reduction
  - Data compression 
---

Summary PCA 
======
I made a [document](https://reda-arab.github.io/files/PCA_explanation_english.pdf) which aims to give an intuitive mathematical explanation of PCA (Principal Component Analysis).

An [French version](https://reda-arab.github.io/files/PCA_Explication_intuitive_francais.pdf) is also available.

Interesting ressources on PCA : 
======
A [very interesting discussion on PCA](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues). The 'top' answer introduces the concept by giving an example of characteristics of wine bottles. 

A [video](https://www.youtube.com/watch?v=FgakZw6K1QQ) on Youtube by StatQuest.

A [post on PCA for Data Science](https://pca4ds.github.io/) by Tomas Aluja-Banetn, Alain Morineau and Gaston Sanchez.

Well-explained lectures by Ryan Tibshirani : [part I](https://reda-arab.github.io/files/07-dim1.pdf), [part II](https://reda-arab.github.io/files/08-dim2.pdf) and [part III](https://reda-arab.github.io/files/09-dim3.pdf). The entire course on Data Mining can be found [here](https://www.stat.cmu.edu/~ryantibs/datamining/lectures/).

